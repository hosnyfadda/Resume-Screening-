{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers gradio PyMuPDF matplotlib spacy pillow -q\n",
        "!python -m spacy download en_core_web_sm -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "M7ABcysioVMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aw2P-xngoQfT"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import fitz\n",
        "import numpy as np\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vxcNIOjyoUSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_file.name) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "    return text.strip() if text.strip() else None"
      ],
      "metadata": {
        "id": "TrC9TVFLoUUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_skills(text):\n",
        "    doc = nlp(text.lower())\n",
        "    skills = set()\n",
        "    for token in doc:\n",
        "        if token.pos_ in [\"NOUN\", \"PROPN\"] and len(token.text) > 2:\n",
        "            skills.add(token.text)\n",
        "    return list(skills)\n"
      ],
      "metadata": {
        "id": "bncqpX78oUb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pie_chart(matched, missing):\n",
        "    labels = ['Matched Skills', 'Missing Skills']\n",
        "    sizes = [len(matched), len(missing)]\n",
        "    if sum(sizes) == 0:\n",
        "        sizes = [1, 1]  # prevent crash if no skills detected\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "    ax.axis('equal')\n",
        "    buffer = BytesIO()\n",
        "    plt.savefig(buffer, format=\"png\")\n",
        "    plt.close(fig)\n",
        "    buffer.seek(0)\n",
        "    return Image.open(buffer)"
      ],
      "metadata": {
        "id": "IrOzUhcboUej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_resume(pdf_file, job_description):\n",
        "    if pdf_file is None:\n",
        "        return \"No resume uploaded.\", None\n",
        "\n",
        "    resume_text = extract_text_from_pdf(pdf_file)\n",
        "    if not resume_text:\n",
        "        return \"No text could be extracted from the resume.\", None\n",
        "\n",
        "    resume_emb = model.encode(resume_text, convert_to_tensor=True)\n",
        "    job_emb = model.encode(job_description, convert_to_tensor=True)\n",
        "    similarity = util.pytorch_cos_sim(resume_emb, job_emb).item()\n",
        "    similarity_percentage = round(similarity * 100, 2)\n",
        "\n",
        "    resume_skills = extract_skills(resume_text)\n",
        "    job_skills = extract_skills(job_description)\n",
        "    matched_skills = [skill for skill in resume_skills if skill in job_skills]\n",
        "    missing_skills = [skill for skill in job_skills if skill not in resume_skills]\n",
        "    chart_img = create_pie_chart(matched_skills, missing_skills)\n",
        "\n",
        "    result = f\"Match Score: {similarity_percentage}%\\nMatched Skills: {matched_skills}\\nMissing Skills: {missing_skills}\"\n",
        "    return result, chart_img\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ðŸ“Œ Resume Screening System with Skills Analysis\")\n",
        "    with gr.Row():\n",
        "        resume_input = gr.File(label=\"Upload Resume (.pdf)\")\n",
        "        job_input = gr.Textbox(label=\"Job Description\", lines=4)\n",
        "    output_text = gr.Textbox(label=\"Result\")\n",
        "    output_image = gr.Image(label=\"Skills Match Chart\", type=\"pil\")\n",
        "    submit_btn = gr.Button(\"Analyze Resume\")\n",
        "    submit_btn.click(analyze_resume, inputs=[resume_input, job_input], outputs=[output_text, output_image])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "mm0RAjFyoUW6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}